services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - BUILD_ENV=production
    container_name: chatbot-app
    restart: unless-stopped
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    environment:
      - ENVIRONMENT=production
      - CHROMA_HOST=chroma
      - CHROMA_PORT=8000
      - LLM_HOST=llm-service
      - LLM_PORT=80
      - LOG_LEVEL=info
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
    depends_on:
      - chroma
      - llm-service

  chroma:
    image: ghcr.io/chroma-core/chroma:latest
    container_name: chromadb
    restart: unless-stopped
    volumes:
      - ./data/chroma:/chroma/chroma
    ports:
      - "8001:8000"
    environment:
      - ALLOW_RESET=true
      - ANONYMIZED_TELEMETRY=false
      - CHROMA_SERVER_AUTH_PROVIDER=chromadb.auth.token.TokenAuthServerProvider
      - CHROMA_SERVER_AUTH_CREDENTIALS_FILE=/chroma/chroma/auth_credentials.json
      - CHROMA_SERVER_AUTH_CREDENTIALS=admin:admin
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/api/v1/heartbeat"]
      interval: 30s
      timeout: 10s
      retries: 3

  llm-service:
    image: ghcr.io/huggingface/text-embeddings-inference:latest
    container_name: llm-embeddings
    restart: unless-stopped
    ports:
      - "8080:80"
    volumes:
      - ./data/models:/data
    environment:
      - MODEL_ID=BAAI/bge-small-en-v1.5
      - REVISION=main
      - MAX_BATCH_TOKENS=16384
      - MAX_INPUT_LENGTH=512
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3